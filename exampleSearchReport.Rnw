\documentclass[a4paper]{article}
\SweaveOpts{echo=FALSE}
\usepackage{a4wide}
\usepackage{color}

<< echo = F >>=
source("TAGS-Based-Scripts/core-TAGSExplorer-API.R")
require(twitteR)
#The original example used the twitteR library to pull in a user stream
#rdmTweets <- userTimeline("psychemedia", n=100)
#Instead, I'm going to pull in a search around a hashtag.
searchTerm='#lak12'
rdmTweets <- searchTwitter(searchTerm, n=1500)
tw.df=twListToDF(rdmTweets)
tw.df$from_user=tw.df$screenName
# Note that the Twitter search API only goes back 1500 tweets (I think?)
df.data=twParse(tw.df)

df.counts=twCounts(df.data)

require(ggplot2)

@

\title{Example Document Summarising Contents of a Twitter Search - #LAK12}
\author{
Tony Hirst\thanks{@psychemedia}\\License: CC-BY
}

\date{\today}


\begin{document}

\maketitle

\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
\renewcommand{\floatpagefraction}{0.75}

\newpage

\section{Twitter Search Summary}
This report has been automatically generated from Twitter data grabbed by a recent results search via the Twitter API.

\subsection{RT Stats}
A series of summary reports around retweet behaviour observed within the search results.

\begin{figure}[htbp]
\begin{center}
<<exampleRTbarchart, fig = T, echo = F>>=
#plot a bar chart of RT of counts
p=ggplot() + geom_bar(aes(x=na.omit(df.data$rtof))) + opts(axis.text.x=theme_text(angle=-90,size=6)) + xlab(NULL)
print(p)
@
\caption{RT bar chart}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
<<exampleSortedRTodbarchart, fig = T, echo = F>>=
#sorted plot based on computed counts - "RT of"
df.data$hrt=barsorter(df.data$rtof)
p=ggplot() + geom_bar(aes(x=na.omit(df.data$hrt))) + opts(axis.text.x=theme_text(angle=-90,size=6)) + xlab(NULL)
print(p)
@
\caption{RT bar chart}
\end{center}
\end{figure}

<<label=table1,echo=FALSE,results=tex>>=
require(xtable)
require(plyr)
print(xtable(head(arrange(df.counts,desc(rtofCount)),10), caption = "Top ten users by 'RT of'' count",caption.placement = "top"))
##But how do we also order the columns, so eg the sortedBy column is first?
@

<<label=table2,echo=FALSE,results=tex>>=
print(xtable(head(arrange(df.counts,desc(toCount)),10), caption = "Top ten users by 'to'' count",caption.placement = "top"))
##But how do we also order the columns, so eg the sortedBy column is first?
@

<<label=table3,echo=FALSE,results=tex>>=
print(xtable(head(arrange(df.counts,desc(rtbyCount)),10), caption = "Top ten users by 'RT by'' count",caption.placement = "top"))
##But how do we also order the columns, so eg the sortedBy column is first?
@

<<label=table4,echo=FALSE,results=tex>>=
print(xtable(head(arrange(df.counts,desc(fromCount)),10), caption = "Top ten users by 'from'' count",caption.placement = "top"))
##But how do we also order the columns, so eg the sortedBy column is first?
@


\begin{figure}[htbp]
\begin{center}
<<exampleSorted2LimitTweetbarchart, fig = T, echo = F>>=
# Limit the data set to show only folk who tweeted twice or more in the sample
counts=table(df.data$screenName)
cc=subset(counts,counts>1)
barplot(cc,las=2,cex.names =0.5)

@
\caption{Folk who tweeted twice or more in the sample}
\end{center}
\end{figure}


\begin{figure}[htbp]
\begin{center}
<<exampleAccession, fig = T, echo = F>>=
tw.dfx=ddply(df.data, .var = "screenName", .fun = function(x) {return(subset(x, created %in% min(created),select=c(screenName,created)))})
## 2) arrange the users in accession order
tw.dfxa=arrange(tw.dfx,-desc(created))
## 3) Use the username accession order to order the screenName factors in the searchlist
df.data$screenName=factor(df.data$screenName, levels = tw.dfxa$screenName)
#ggplot seems to be able to cope with time typed values...
p=ggplot(df.data)+geom_point(aes(x=created,y=screenName))
p=p+opts(axis.text.y=theme_text(size=5))
print(p)
@
\caption{Accession order of tweeps}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
<<exampleAccessionRT, fig = T, echo = F>>=

df.data$rtt=sapply(df.data$rtof,function(rt) if (is.na(rt)) 'T' else 'RT')
p=ggplot(df.data)+geom_point(aes(x=created,y=screenName,col=rtt))
p=p+opts(axis.text.y=theme_text(size=5))
print(p)
@
\caption{Accession of tweeps (highlighting old style RTs)}
\end{center}
\end{figure}


\begin{figure}[htbp]
\begin{center}
<<wordcloud, fig = T, echo = F>>=
RemoveAtPeople <- function(tweet) {
  gsub("@\\w+", "", tweet)
}

tweets <- as.vector(sapply(df.data$text, RemoveAtPeople))

require(tm)
generateCorpus= function(df,my.stopwords=c()){
  #Install the textmining library
  tw.corpus= Corpus(VectorSource(df))
  # remove punctuation
  ## I wonder if it would make sense to remove @d names first?
  tw.corpus = tm_map(tw.corpus, removePunctuation)
  #normalise case
  tw.corpus = tm_map(tw.corpus, tolower)
  # remove stopwords
  tw.corpus = tm_map(tw.corpus, removeWords, stopwords('english'))
  tw.corpus = tm_map(tw.corpus, removeWords, my.stopwords)

  tw.corpus
}

wordcloud.generate=function(corpus,min.freq=3){
  require(wordcloud)
  doc.m = TermDocumentMatrix(corpus, control = list(minWordLength = 1))
  dm = as.matrix(doc.m)
  # calculate the frequency of words
  v = sort(rowSums(dm), decreasing=TRUE)
  d = data.frame(word=names(v), freq=v)
  wc=wordcloud(d$word, d$freq, min.freq=min.freq)
  wc
}

print(wordcloud.generate(generateCorpus(tweets,'cetis12'),7))
@
\caption{Wordcloud of tweets with @usernames excluded)}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
<<exampleHashtagCount, fig = T, echo = F>>=
#hashtag processing via http://stackoverflow.com/a/9360445/454773
hashtagAugment=function(tmp){
  #I think we need to defend against cases with zero tagged or untagged tweets?
  tags <- str_extract_all(tmp$text, '#[a-zA-Z0-9]+')
  index <- rep.int(seq_len(nrow(tmp)), sapply(tags, length))
  if (length(index)!=0 || index ){
    tagged <- tmp[index, ]
    tagged$tag <- unlist(tags)
  } else {tagged=data.frame()}
  has_no_tag <- sapply(tags, function(x) length(x) == 0L)
  not_tagged <- tmp[has_no_tag, ]
  rbind(tagged, not_tagged)
}
df.data.t=hashtagAugment(df.data)

p=ggplot(df.data.t,aes(x=na.omit(tag)))+geom_bar(aes(y=(..count..))) + xlab(NULL) + opts(axis.text.x=theme_text(angle=-90,size=6))

print(p)
@
\caption{Example hashtag count}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
<<exampleHashtagOverTime, fig = T, echo = F>>=
#Order the tag factor levels in the order in which they were first created
tw.dfx=ddply(df.data.t, .var = "tag", .fun = function(x) {return(subset(x, created %in% min(created),select=c(tag,created)))})
tw.dfxa=arrange(tw.dfx,-desc(created))
df.data.t$tag=factor(df.data.t$tag, levels = tw.dfxa$tag)

#and plot the result
p=ggplot(df.data.t)+geom_point(aes(x=created,y=tag))
print(p)
@
\caption{Hashtag Usage Over Time}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
<<exampleTweetsTimeseries, fig = T, echo = F>>=
require(xts)
#The xts function creates a timeline from a vector of values and a vector of timestamps.
#If we know how many tweets we have, we can just create a simple list or vector containing that number of 1s
ts=xts(rep(1,times=nrow(df.data)),df.data$created)

#We can now do some handy number crunching on the timeseries, such as applying a formula to values contained with day, week, month, quarter or year time bins.
#So for example, if we sum the unit values in daily bin, we can get a count of the number of tweets per day
ts.sum=apply.daily(ts,sum) 
#also apply. weekly, monthly, quarterly, yearly

#If for any resason we need to turn the timeseries into a dataframe, we can:
#http://stackoverflow.com/a/3387259/454773
ts.sum.df=data.frame(date=index(ts.sum), coredata(ts.sum))

colnames(ts.sum.df)=c('date','sum')

#We can then use ggplot to plot the timeseries...
p=ggplot(ts.sum.df)+geom_line(aes(x=date,y=sum))

print(p)
@
\caption{Tweeting activity}
\end{center}
\end{figure}

\end{document}